from google import genai
from google.genai import types
from PIL import Image, ImageDraw, ImageFont
from PIL import Image
from io import BytesIO
import torch
import cv2
import numpy as np
from torchvision import transforms, utils, models
from utils.data_process import preprocess_img, postprocess_img
from PIL import Image


def generate_image_from_quiz():
    try:
        client = genai.Client()

        print("ã‚¯ã‚¤ã‚ºã®æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        question = input("å•é¡Œæ–‡: ")
        answer = input("è§£ç­”: ")

        prompt = (
            f"""
                ã“ã‚Œã‹ã‚‰ã‚¯ã‚¤ã‚ºã®å•é¡Œæ–‡ã¨è§£ç­”ã‚’å…¥åŠ›ã™ã‚‹ã®ã§ã€ãã‚Œã‚‰ã‚’å‚è€ƒã«å•é¡Œæ–‡ã‚’å¿ å®Ÿã«èª¬æ˜ã™ã‚‹ã‚¤ãƒ©ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
                ç”Ÿæˆã™ã‚‹ç”»åƒå†…ã«ã¯æ–‡å­—ã¯å«ã¾ãªã„ã§ãã ã•ã„ã€‚
                ã¾ãŸç”»åƒä»¥å¤–ï¼ˆèª¬æ˜æ–‡ãªã©ï¼‰ã¯å‡ºåŠ›ã›ãšã€ç”Ÿæˆã—ãŸç”»åƒã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
                ã¾ãŸãªã‚‹ã¹ãç©ºç™½éƒ¨åˆ†ãŒå°‘ãªããªã‚‹ã‚ˆã†ã«ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
                [å•é¡Œæ–‡]
                {question}

                [è§£ç­”]
                {answer}
                """
        )

        print("\nç”»åƒã‚’ç”Ÿæˆä¸­ã§ã™...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚")

        response = client.models.generate_content(
            model="gemini-2.5-flash-image",
            contents=[prompt],
        )


        for part in response.candidates[0].content.parts:
            # å›ç­”ã®ï¼‘ç•ªç›®ã®å€™è£œã®å†…å®¹ã®è¦ç´ ã®ã‚¯ãƒ©ã‚¹ã‚’æŠ½å‡ºã—ã¦ã„ã‚‹
            if part.text is not None:
                print(part.text)
                return None, None
            if part.inline_data is not None:
                # ç”»åƒã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ
                image = Image.open(BytesIO(part.inline_data.data))
                output_filename = "generated_image.png"
                image.save(output_filename)
                print(f"GeminiãŒç”Ÿæˆã—ãŸç”»åƒã‚’'{output_filename}'ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸ")
                return image, answer

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

if __name__ == "__main__":

    generated_pil_image, answer_text = generate_image_from_quiz()

    if generated_pil_image is None:
        print("ç”»åƒã®ç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    else:
        generated_image_path = "generated_image.png"
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        print(f"CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}")

        flag = 1 # 0 for TranSalNet_Dense, 1 for TranSalNet_Res

        if flag:
            from TranSalNet_Res import TranSalNet
            model = TranSalNet()
            model.load_state_dict(torch.load(r'pretrained_models\TranSalNet_Res.pth'))
        else:
            from TranSalNet_Dense import TranSalNet
            model = TranSalNet()
            model.load_state_dict(torch.load(r'pretrained_models\TranSalNet_Dense.pth'))

        model = model.to(device) 
        model.eval()

        img = preprocess_img(generated_image_path) # padding and resizing input image into 384x288
        img = np.array(img)/255.
        img = np.expand_dims(np.transpose(img,(2,0,1)),axis=0)
        img = torch.from_numpy(img).type(torch.cuda.FloatTensor).to(device)
        pred_saliency_tensor = model(img)
        toPIL = transforms.ToPILImage()
        pic = toPIL(pred_saliency_tensor.squeeze())

        saliency_map_np = postprocess_img(pic, generated_image_path)
        saliency_output_filename = r'example/result_saliency.png'
        cv2.imwrite(saliency_output_filename, saliency_map_np, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
        print(f"Saliency Mapã‚’ '{saliency_output_filename}' ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚")

        # ----- 2. æœ€ã‚‚æ³¨è¦–ã•ã‚Œã‚‹å ´æ‰€ã®åº§æ¨™ã‚’å–å¾— -----
        # saliency_map_np (NumPyé…åˆ—) ã®ä¸­ã§æœ€ã‚‚å€¤ãŒå¤§ãã„å ´æ‰€ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹(y, x)ã‚’è¦‹ã¤ã‘ã‚‹
        max_loc_flat = np.argmax(saliency_map_np) #1æ¬¡å…ƒé…åˆ—ã¨ã—ã¦è€ƒãˆãŸæ™‚ã«æœ€å¤§å€¤ãŒã‚ã‚‹å ´æ‰€ã‚’ç¤ºã™
        max_y, max_x = np.unravel_index(max_loc_flat, saliency_map_np.shape) # 2æ¬¡å…ƒé…åˆ—ã®æ™‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™
        print(f"ğŸ’¡ æœ€ã‚‚æ³¨è¦–ã•ã‚Œã‚‹åº§æ¨™ (x, y): ({max_x}, {max_y})")

        # ----- 3. å…ƒç”»åƒã«è§£ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”» -----
        # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆï¼è¦å¤‰æ›´ï¼ï¼‰
        # ãŠä½¿ã„ã®ç’°å¢ƒã«åˆã‚ã›ã¦æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„
        font_path = "C:/Windows/Fonts/meiryo.ttc"
        font_size = 40
        try:
            font = ImageFont.truetype(font_path, font_size)
        except IOError:
            print(f"è­¦å‘Š: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ³ãƒˆ '{font_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            font = ImageFont.load_default()

        # æç”»ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        draw = ImageDraw.Draw(generated_pil_image)

        # ãƒ†ã‚­ã‚¹ãƒˆã®æç”»ã‚µã‚¤ã‚ºã‚’å–å¾—ã—ã¦ä¸­å¤®æƒãˆã®ãŸã‚ã®ä½ç½®ã‚’è¨ˆç®—
        text_bbox = draw.textbbox((0, 0), answer_text, font=font)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]
        text_x = max_x - (text_width / 2)
        text_y = max_y - (text_height / 2)

        # ãƒ†ã‚­ã‚¹ãƒˆã«å½±ã‚’ã¤ã‘ã¦è¦‹ã‚„ã™ãã™ã‚‹
        shadow_color = "black"
        for offset in range(1, 3):
             draw.text((text_x - offset, text_y - offset), answer_text, font=font, fill=shadow_color)
             draw.text((text_x + offset, text_y - offset), answer_text, font=font, fill=shadow_color)
             draw.text((text_x - offset, text_y + offset), answer_text, font=font, fill=shadow_color)
             draw.text((text_x + offset, text_y + offset), answer_text, font=font, fill=shadow_color)

        # ãƒ†ã‚­ã‚¹ãƒˆæœ¬ä½“ã‚’æç”»
        text_color = "white"
        draw.text((text_x, text_y), answer_text, font=font, fill=text_color)

        # ----- 4. æœ€çµ‚ç”»åƒã‚’ä¿å­˜ -----
        final_output_filename = "final_result_with_answer.png"
        generated_pil_image.save(final_output_filename)
        print(f"ğŸ‰ å®Œæˆï¼è§£ç­”ãƒ†ã‚­ã‚¹ãƒˆä»˜ãç”»åƒã‚’ '{final_output_filename}' ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚")